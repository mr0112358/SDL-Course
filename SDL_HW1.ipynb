{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDL-HW1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2vOCMbnnuTGAEomlP4x0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr0112358/SDL-Course/blob/master/SDL_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rii16tv_Vzj4"
      },
      "source": [
        "# Problem 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CR1pTOVbGlj"
      },
      "source": [
        "## Part (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAb1pJ9IWEti"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I5x3qU0Vywb"
      },
      "source": [
        "def sigm(s): # Define sigmoid function\n",
        "  return 1.0/(1 +np.e**-s)\n",
        "\n",
        "def dsigm(s): # Derivative of sigmoid function\n",
        "  return sigm(s) * (1-sigm(s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB673CctW3A5"
      },
      "source": [
        "W1 = np.array([[1.5, 2.5, 1.0],[2.0, -1.5, -3.0]]) # [[w_h1b, w_h1x1, w_h1x2],[w_h2b, w_h2x1, w_h2x2]]\n",
        "W2 = np.array([-1.0, 1.0, 0.5])                    # [w_yb, w_yh1, w_yh2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fr_2LSfWL0I"
      },
      "source": [
        "# Input Layer\n",
        "x1 = 0; x2 = 1\n",
        "X = np.array([1.0, x1, x2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGwhnUu5ZHZk",
        "outputId": "e0617594-a71c-4b49-ecbb-115213be95b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Layer 1\n",
        "H = np.append(1, sigm(np.dot(W1,X))) # H = [1, h1, h2]\n",
        "H"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.92414182, 0.26894142])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il4kLVIDaoKi",
        "outputId": "f2ce7229-607e-4fd7-e608-8a51eba8418c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = sigm(np.dot(W2,H))\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5146489391238233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVCYXHUZbMfg"
      },
      "source": [
        "## Part (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2o_ynrcdxMp"
      },
      "source": [
        "O = 1.0 # The target output\n",
        "dE_dy = y - O # E = (y-O)^2 / 2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV735cvqbRmr",
        "outputId": "e1506ccb-618d-4a51-d37b-cacf652d0686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dy_dW2 = dsigm(np.dot(W2,H)) * H\n",
        "dy_dW2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.24978541, 0.23083714, 0.06717764])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP69lEdvehmO",
        "outputId": "cf3a9ddb-6cfe-4080-977d-9371443fd2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dE_dW2 = dE_dy * dy_dW2\n",
        "dE_dW2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.12123361, -0.11203705, -0.03260474])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVy_zlb-etVN",
        "outputId": "1d6283cd-0bf8-4e0d-8b43-02dc51a82998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dh_dW1 = np.outer(dsigm(np.dot(W1,X)), X) # h=(h1, h2)\n",
        "dh_dW1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07010372, 0.        , 0.07010372],\n",
              "       [0.19661193, 0.        , 0.19661193]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6OxYlBpgf6_",
        "outputId": "7d2239cf-4139-428b-8e4d-f16f805c7d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dy_dh = np.delete(dsigm(np.dot(W2,H)) * W2, 0)\n",
        "dy_dh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.24978541, 0.1248927 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh8tiWZfgQqt",
        "outputId": "102f44bb-e924-46c3-cf52-88df2d4c0409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dE_dW1 = np.diag(dE_dy * dy_dh) @ dh_dW1\n",
        "dE_dW1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00849893,  0.        , -0.00849893],\n",
              "       [-0.01191799,  0.        , -0.01191799]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35OrPoZpiRI2",
        "outputId": "62bea8ea-904d-4b85-fb2e-01a06a4d0da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# One step update of Weights\n",
        "alpha = 0.1\n",
        "W2_new = W2 - alpha * dE_dW2\n",
        "print(\"New W2 is \", W2_new)\n",
        "W1_new = W1 - alpha * dE_dW1\n",
        "print(\"New W1 is \", W1_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New W2 is  [-0.98787664  1.01120371  0.50326047]\n",
            "New W1 is  [[ 1.50084989  2.5         1.00084989]\n",
            " [ 2.0011918  -1.5        -2.9988082 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vuw3-6yV0Rt"
      },
      "source": [
        "# Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHopv-mF0Se9"
      },
      "source": [
        "## Tensor Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu79gQKupYvQ",
        "outputId": "9dc572d6-741c-41ab-a374-de0b2d5913af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# First import torch and check if GPU or TPU is avaliable. To accelerate by GPU or TPU, try Runtime -> Change runtime type\n",
        "import torch as tr\n",
        "print(tr.__version__)\n",
        "if tr.cuda.is_available:\n",
        "  print('cuda is avaliable')\n",
        "else:\n",
        "  print('cuda is no avaliable')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0+cu101\n",
            "cuda is avaliable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZUN5XlkwiRd",
        "outputId": "cace1ebd-7e19-4542-9841-1e4b0192600e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Create a 2x3 tensor\n",
        "x = tr.tensor([[1,2,3],[4,5,6]], device = 'cuda', dtype=tr.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1TkuMje0-gm",
        "outputId": "3446fa75-d440-4e95-8d59-6346fbf1ed9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "print(x,\"\\n\")\n",
        "print(x.type(),\"\\n\")\n",
        "print(x.size(),\"\\n\")\n",
        "print(x.shape,\"\\n\")\n",
        "print(x.dim(),\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], device='cuda:0') \n",
            "\n",
            "torch.cuda.FloatTensor \n",
            "\n",
            "torch.Size([2, 3]) \n",
            "\n",
            "torch.Size([2, 3]) \n",
            "\n",
            "2 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqKLNxHn1wx-",
        "outputId": "52652082-13df-4632-88ee-b0eab379877a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Access elements\n",
        "print('x[0,1]: ', x[0,1])\n",
        "print('type(x[0,1]): ', type(x[0,1]))   # Still of torch type\n",
        "print('type(x[0,1].item()): ', type(x[0,1].item())) #convert this to a Python scalar using the .item() method"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x[0,1]:  tensor(2., device='cuda:0')\n",
            "type(x[0,1]):  <class 'torch.Tensor'>\n",
            "type(x[0,1].item()):  <class 'float'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hz-N4yU2r6o"
      },
      "source": [
        "\n",
        "## Tensor constructors\n",
        "\n",
        "PyTorch provides many convenience methods for constructing tensors; this avoids the need to use Python lists. For example:\n",
        "\n",
        "- `torch.zeros`: Creates a tensor of all zeros\n",
        "- `torch.ones`: Creates a tensor of all ones\n",
        "- `torch.eye`: Creates a tensor of identity matrix\n",
        "- `torch.rand`: Creates a tensor with uniform random numbers\n",
        "\n",
        "You can find a full list of tensor creation operations in the [documentation](https://pytorch.org/docs/1.1.0/torch.html#creation-ops).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuaVwdMPzXT0",
        "outputId": "ae6425bd-4d3a-4ffb-ecf1-4605eb09cec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "# Create a tensor of all zeros\n",
        "a = tr.zeros(2, 3, 4)\n",
        "print('tensor of zeros:',a,'\\n')\n",
        "\n",
        "# Create a tensor of all ones\n",
        "b = tr.ones(1, 2)\n",
        "print('\\ntensor of ones:',b,'\\n')\n",
        "\n",
        "# Create a 3x3 identity matrix\n",
        "c = tr.eye(3)\n",
        "print('\\nidentity matrix:',c,'\\n')\n",
        "\n",
        "# Tensor of random values\n",
        "d = tr.rand(3, 2, 2)\n",
        "print('\\nrandom tensor:',d,'\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor of zeros: tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]]) \n",
            "\n",
            "\n",
            "tensor of ones: tensor([[1., 1.]]) \n",
            "\n",
            "\n",
            "identity matrix: tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]]) \n",
            "\n",
            "\n",
            "random tensor: tensor([[[0.8437, 0.9969],\n",
            "         [0.2623, 0.1718]],\n",
            "\n",
            "        [[0.2050, 0.5188],\n",
            "         [0.6297, 0.4958]],\n",
            "\n",
            "        [[0.3907, 0.6631],\n",
            "         [0.3650, 0.4924]]]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqneYOst3ktH"
      },
      "source": [
        "## Pytorch Data Type\n",
        "We can cast a tensor to another datatype using the `.to()` method; there are also convenience methods like `.float()` and `.long()` that cast to particular datatypes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljzn9j2G6AjR",
        "outputId": "6dde8b71-1d63-41d1-9fbe-12e53a1c232a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "x0 = tr.eye(3, dtype=tr.int64)\n",
        "x1 = x0.float()  # Cast to 32-bit float\n",
        "x2 = x0.double() # Cast to 64-bit float\n",
        "x3 = x0.to(tr.float32) # Alternate way to cast to 32-bit float\n",
        "x4 = x0.to(tr.float64) # Alternate way to cast to 64-bit float\n",
        "print('x0:', x0.dtype)\n",
        "print('x1:', x1.dtype)\n",
        "print('x2:', x2.dtype)\n",
        "print('x3:', x3.dtype)\n",
        "print('x4:', x4.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0: torch.int64\n",
            "x1: torch.float32\n",
            "x2: torch.float64\n",
            "x3: torch.float32\n",
            "x4: torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ3nKl3c6TIs"
      },
      "source": [
        "\n",
        "\n",
        "PyTorch provides several ways to create a tensor with the same datatype as another tensor:\n",
        "\n",
        "- PyTorch provides tensor constructors such as `torch.new_zeros()` that create new tensors with the same shape and type as a given tensor\n",
        "- Tensor objects have instance methods such as `.new_zeros()` that create tensors the same type but possibly different shapes\n",
        "- The tensor instance method `.to()` can take a tensor as an argument, in which case it casts to the datatype of the argument.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd8P0JCH6dN5",
        "outputId": "c1a9e134-8413-4120-cf00-e7ecee4dfaaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "x0 = tr.eye(3, dtype=tr.float32)  # Shape (3, 3), dtype torch.float64\n",
        "x1 = tr.zeros_like(x0)               # Shape (3, 3), dtype torch.float64\n",
        "x2 = x0.new_zeros(4, 5)                 # Shape (4, 5), dtype torch.float64\n",
        "x3 = tr.ones(6, 7).to(x0)            # Shape (6, 7), dtype torch.float64)\n",
        "print('x0 shape is %r, dtype is %r' % (x0.shape, x0.dtype))\n",
        "print('x1 shape is %r, dtype is %r' % (x1.shape, x1.dtype))\n",
        "print('x2 shape is %r, dtype is %r' % (x2.shape, x2.dtype))\n",
        "print('x3 shape is %r, dtype is %r' % (x3.shape, x3.dtype))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x0 shape is torch.Size([3, 3]), dtype is torch.float32\n",
            "x1 shape is torch.Size([3, 3]), dtype is torch.float32\n",
            "x2 shape is torch.Size([4, 5]), dtype is torch.float32\n",
            "x3 shape is torch.Size([6, 7]), dtype is torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYmjZvpd61uL"
      },
      "source": [
        "\n",
        "## Tensor indexing\n",
        "\n",
        "Given index arrays idx0 and idx1 with N elements each, `a[idx0, idx1]` is equivalent to:\n",
        "```\n",
        "torch.tensor([\n",
        "  a[idx0[0], idx1[0]],\n",
        "  a[idx0[1], idx1[1]],\n",
        "  ...,\n",
        "  a[idx0[N - 1], idx1[N - 1]]\n",
        "])\n",
        "```\n",
        "(A similar pattern extends to tensors with more than two dimensions)\n",
        "\n",
        "Boolean tensor indexing lets you pick out arbitrary elements of a tensor according to a boolean mask. Frequently this type of indexing is used to select or modify the elements of a tensor that satisfy some condition.\n",
        "\n",
        "In PyTorch, we use tensors of dtype `torch.uint8` to hold boolean masks; 0 means false and 1 means true."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USNxVqCG68M9",
        "outputId": "d8bcbfcb-ecad-4cf0-c7b4-d81e07690330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "a = tr.tensor([[1,2], [3, 4], [5, 6]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "print(a[[1,-1],[0,0]])\n",
        "print(a[1:2,0:])\n",
        "\n",
        "# Find the elements of a that are bigger than 3. The mask has the same shape as\n",
        "# a, where each element of mask tells whether the corresponding element of a\n",
        "# is greater than three.\n",
        "mask = (a > 3)\n",
        "print('\\nMask tensor:')\n",
        "print(mask)\n",
        "# Check type of mask\n",
        "print('\\n', mask.type())\n",
        "\n",
        "# We can use the mask to construct a rank-1 tensor containing the elements of a\n",
        "# that are selected by the mask\n",
        "print('\\nSelecting elements with the mask:')\n",
        "print(a[mask])\n",
        "\n",
        "# We can also use boolean masks to modify tensors; for example this sets all\n",
        "# elements <= 3 to zero:\n",
        "a[a <= 3] = 0\n",
        "print('\\nAfter modifying with a mask:')\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([3, 5])\n",
            "tensor([[3, 4]])\n",
            "\n",
            "Mask tensor:\n",
            "tensor([[False, False],\n",
            "        [False,  True],\n",
            "        [ True,  True]])\n",
            "\n",
            " torch.BoolTensor\n",
            "\n",
            "Selecting elements with the mask:\n",
            "tensor([4, 5, 6])\n",
            "\n",
            "After modifying with a mask:\n",
            "tensor([[0, 0],\n",
            "        [0, 4],\n",
            "        [5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCGl5HDi28dG"
      },
      "source": [
        "\n",
        "## Reshaping operations\n",
        "View\n",
        "\n",
        "PyTorch provides many ways to manipulate the shapes of tensors. The simplest example is `.view()`: This returns a new tensor with the same number of elements as its input, but with a different shape.\n",
        "\n",
        "We can use `.view()` to flatten matrices into vectors, and to convert rank-1 vectors into rank-2 row or column matrices:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD-ATJZFN5OD",
        "outputId": "77ebf513-5c4e-471a-e9d9-00997a13e29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "x0 = tr.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "print('Original tensor:')\n",
        "print(x0)\n",
        "print('shape:', x0.shape)\n",
        "\n",
        "# Flatten x0 into a rank 1 vector of shape (8,)\n",
        "x1 = x0.view(8)\n",
        "print('\\nFlattened tensor:')\n",
        "print(x1)\n",
        "print('shape:', x1.shape)\n",
        "\n",
        "# Convert x1 to a rank 2 \"row vector\" of shape (1, 8)\n",
        "x2 = x1.view(1, 8)\n",
        "print('\\nRow vector:')\n",
        "print(x2)\n",
        "print('shape:', x2.shape)\n",
        "\n",
        "# Convert x1 to a rank 2 \"column vector\" of shape (8, 1)\n",
        "x3 = x1.view(8, 1)\n",
        "print('\\nColumn vector:')\n",
        "print(x3)\n",
        "print('shape:', x3.shape)\n",
        "\n",
        "# Convert x1 to a rank 3 tensor of shape (2, 2, 2):\n",
        "x4 = x1.view(2, 2, 2)\n",
        "print('\\nRank 3 tensor:')\n",
        "print(x4)\n",
        "print('shape:', x4.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "shape: torch.Size([2, 4])\n",
            "\n",
            "Flattened tensor:\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
            "shape: torch.Size([8])\n",
            "\n",
            "Row vector:\n",
            "tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
            "shape: torch.Size([1, 8])\n",
            "\n",
            "Column vector:\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6],\n",
            "        [7],\n",
            "        [8]])\n",
            "shape: torch.Size([8, 1])\n",
            "\n",
            "Rank 3 tensor:\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "shape: torch.Size([2, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsIuJjzB3iNX"
      },
      "source": [
        "\n",
        "### Swapping axes\n",
        "\n",
        "Another common reshape operation you might want to perform is transposing a matrix. You might be surprised if you try to transpose a matrix with `.view()`: The `view()` function takes elements in row-major order, so you cannot transpose matrices with `.view()`.\n",
        "\n",
        "In general, you should only use .view() to add new dimensions to a tensor, or to collapse adjacent dimensions of a tensor.\n",
        "\n",
        "For other types of reshape operations, you usually need to use a function that can swap axes of a tensor. The simplest such function is `.t()`, specificially for transposing matrices. It is available both as a [function in the torch module](https://pytorch.org/docs/1.1.0/torch.html#torch.t), and as a [tensor instance method](https://pytorch.org/docs/1.1.0/tensors.html#torch.Tensor.t):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIovEvv_8Dkm",
        "outputId": "bc4ee553-80d6-4e47-dd51-ff8f6e4c2a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "x = tr.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print('Original matrix:')\n",
        "print(x)\n",
        "print('\\nTransposing with view DOES NOT WORK!')\n",
        "print(x.view(3, 2))\n",
        "print('\\nTransposed matrix:')\n",
        "print(tr.t(x))\n",
        "print(x.t())\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original matrix:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Transposing with view DOES NOT WORK!\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Transposed matrix:\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQY60XXb4Hp2"
      },
      "source": [
        "\n",
        "### Contiguous tensors\n",
        "\n",
        "Some combinations of reshaping operations will fail with cryptic errors. The exact reasons for this have to do with the way that tensors and views of tensors are implemented, and are beyond the scope of this assignment. However if you're curious, [this blog post by Edward Yang](http://blog.ezyang.com/2019/05/pytorch-internals/) gives a clear explanation of the problem.\n",
        "\n",
        "What you need to know is that you can typically overcome these sorts of errors by either by calling `.contiguous()` before `.view()`, or by using `.reshape()` instead of `.view()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQRDrGdR4Zdf",
        "outputId": "ba42a823-b8c4-4971-f2c6-4785e2ff6e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "x0 = tr.randn(2, 3, 4)\n",
        "\n",
        "try:\n",
        "  # This sequence of reshape operations will crash\n",
        "  x1 = x0.transpose(1, 2).view(8, 3)\n",
        "except RuntimeError as e:\n",
        "  print(type(e), e)\n",
        "  \n",
        "# We can solve the problem using either .contiguous() or .reshape()\n",
        "x1 = x0.transpose(1, 2).contiguous().view(8, 3)\n",
        "x2 = x0.transpose(1, 2).reshape(8, 3)\n",
        "print('x1 shape: ', x1.shape)\n",
        "print('x2 shape: ', x2.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'RuntimeError'> view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
            "x1 shape:  torch.Size([8, 3])\n",
            "x2 shape:  torch.Size([8, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZr-O1_b413p"
      },
      "source": [
        "\n",
        "## Tensor operations\n",
        "### Elementwise operations\n",
        "\n",
        "Basic mathematical functions operate elementwise on tensors, and are available as operator overloads, as functions in the torch module, and as instance methods on torch objects; all produce the same results:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vryrhiWs46zD",
        "outputId": "20e29762-cc6d-43b6-81b7-17917be2a62d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "x = tr.tensor([[1, 2, 3, 4]], dtype=tr.float32)\n",
        "y = tr.tensor([[5, 6, 7, 8]], dtype=tr.float32)\n",
        "\n",
        "# Elementwise sum; all give the same result\n",
        "print('Elementwise sum:')\n",
        "print(x + y)\n",
        "print(tr.add(x, y))\n",
        "print(x.add(y))\n",
        "\n",
        "# Elementwise difference\n",
        "print('\\nElementwise difference:')\n",
        "print(x - y)\n",
        "print(tr.sub(x, y))\n",
        "print(x.sub(y))\n",
        "\n",
        "# Elementwise product\n",
        "print('\\nElementwise product:')\n",
        "print(x * y)\n",
        "print(tr.mul(x, y))\n",
        "print(x.mul(y))\n",
        "\n",
        "# Elementwise division\n",
        "print('\\nElementwise division')\n",
        "print(x / y)\n",
        "print(tr.div(x, y))\n",
        "print(x.div(y))\n",
        "\n",
        "# Elementwise power\n",
        "print('\\nElementwise power')\n",
        "print(x ** y)\n",
        "print(tr.pow(x, y))\n",
        "print(x.pow(y))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elementwise sum:\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "\n",
            "Elementwise difference:\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "\n",
            "Elementwise product:\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "\n",
            "Elementwise division\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "\n",
            "Elementwise power\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v8fgkpG8uGj"
      },
      "source": [
        "# Einstein Notation (`einsum`)\n",
        "In mathematics, especially in applications of linear algebra to physics, the Einstein notation or Einstein summation convention is a notational convention that implies summation over a set of indexed terms in a formula, thus achieving notational brevity.\n",
        "\n",
        "Einsum is implemented in numpy via `np.einsum`, in PyTorch via `torch.einsum`, and in TensorFlow via `tf.einsum`. All three einsum functions share the same signature `einsum(equation,operands)` where `equation` is a string representing the Einstein summation and operands is a sequence of tensors. Check [tech blog by Tim Rocktäschel](https://rockt.github.io/2018/04/30/einsum).\n",
        "\n",
        "For instance, our first example $c_j=\\sum_i\\sum_k A_{ik}B_{kj}$ can be written as the equation string `\"ik,kj -> j\"`. Note that the naming of the indices $(i, j, k)$ is arbitrary but it needs to be used consistently. \n",
        "\n",
        " What's great about having einsum not only in numpy but also in PyTorch and TensorFlow is that it can be used in arbitrary computation graphs for neural network architectures and that we can backpropagate through it. A typical call to einsum has the following form\n",
        "$$result=einsum(\"◻◻,◻◻◻,◻◻->◻◻\",arg1,arg2,arg3)$$\n",
        "where $◻$ is a placeholder for a character identifying a tensor dimension. From this equation string we can infer that `arg1` and `arg3` are matrices, `arg2` is an order-3 tensor, and that the result of this einsum operation is a matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S1JJt0o-PC2"
      },
      "source": [
        "## 1 Matrix Transpose\n",
        "$$B_{ji}=A_{ij}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwAww6fM-Xbd",
        "outputId": "fd07cba8-5e39-4207-9115-78fb10a7f267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "a = tr.arange(6).reshape(2,3)\n",
        "print(a)\n",
        "b = tr.einsum('ij->ji', a)\n",
        "print(b)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ArnQ5JD-zpf"
      },
      "source": [
        "## 2. Sum\n",
        "### 2.1 Total Summation\n",
        "$$\\sum_i\\sum_j A_{ij}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtVUA8dg_IHP",
        "outputId": "592a13b0-6a60-4547-bda7-96452d2a38fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tr.einsum('ij->',a)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPAvhUf9_RLn"
      },
      "source": [
        "### 2.2 Column Sum\n",
        "$$b_j = \\sum_i A_{ij}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEQ9EdpU_ZQU",
        "outputId": "7d27fec8-e2ec-43f8-f2ff-6a4f54b12832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tr.einsum('ij->j',a)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 5, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XI5Msjj__7h"
      },
      "source": [
        "### 2.3 Row Sum\n",
        "$$a_i = \\sum_j A_{ij}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mu-MPymAPrX",
        "outputId": "e0e8ffb6-eaf2-4b5a-806f-4a553d22282a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tr.einsum('ij->i',a)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u7JicnyAUDV"
      },
      "source": [
        "### 2.4 Matrix times Vector\n",
        "$c_i = \\sum_j A_{ij}b_j:=A_{ij}b_j$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9nlZSLnAxpH",
        "outputId": "85f93138-7f74-4466-da19-505cfbda8bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "A = tr.arange(6).reshape(2,3)\n",
        "b = tr.arange(3)\n",
        "c = tr.einsum('ij,j->i',A,b)\n",
        "print(\"A:\",A)\n",
        "print(\"b:\",b)\n",
        "print(\"c:\",c)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "b: tensor([0, 1, 2])\n",
            "c: tensor([ 5, 14])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5wrtmJjBg5C"
      },
      "source": [
        "### 2.5 Matrix times Matrix\n",
        "$$C_{ij} = \\sum_k A_{ik}B_{kj}:=A_{ik}B_{kj}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrU5IekSBybn",
        "outputId": "0d2f4763-7563-4c0a-9a67-eb4805eace5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "A = tr.arange(6).reshape(2,3)\n",
        "B = tr.arange(12).reshape(3,4)\n",
        "C = tr.einsum('ik,kj->ij',A,B)\n",
        "print(\"A:\",A)\n",
        "print(\"B:\",B)\n",
        "print(\"C:\",C)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "B: tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "C: tensor([[20, 23, 26, 29],\n",
            "        [56, 68, 80, 92]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvncxKWzCNLI"
      },
      "source": [
        "### 2.6 Dot Product\n",
        "$$c = \\sum_i\\sum_j A_{ij}B_{ij}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S31PZvqgCsVq",
        "outputId": "9c255d11-0b19-4a83-8975-aa6a412624b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "A = tr.arange(6).reshape(2,3)\n",
        "B = tr.arange(6).reshape(2,3)\n",
        "c = tr.einsum('ik,ik->',A,B)\n",
        "print(\"A:\",A)\n",
        "print(\"B:\",B)\n",
        "print(\"c:\",c)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "B: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "c: tensor(55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X5YUNzoC6W3"
      },
      "source": [
        "### 2.7 Hadamard Product\n",
        "$$C_{ij} = A_{ij}B_{ij}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDWWTOgoDLMI",
        "outputId": "c34b44ef-a78d-4867-a5bf-26bae2c7741e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "A = tr.arange(6).reshape(2,3)\n",
        "B = tr.arange(6).reshape(2,3)\n",
        "C = tr.einsum('ij,ij->ij',A,B)\n",
        "print(\"A:\",A)\n",
        "print(\"B:\",B)\n",
        "print(\"C:\",C)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "B: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "C: tensor([[ 0,  1,  4],\n",
            "        [ 9, 16, 25]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH8dg_MjDejo"
      },
      "source": [
        "### 2.8 Outer Product\n",
        "$$C_{ij} = a_i b_j $$\n",
        "$$\\text{i.e., }C = ab^{\\intercal}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aeZ-cFtDS2k",
        "outputId": "3c7bdc44-9dad-4ced-9500-c3c8b67857c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "a = tr.arange(3)\n",
        "b = tr.arange(3,7)  # -- a vector of length 4 containing [3, 4, 5, 6]\n",
        "print(a)\n",
        "print(b)\n",
        "tr.einsum('i,j->ij', [a, b])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2])\n",
            "tensor([3, 4, 5, 6])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0],\n",
              "        [ 3,  4,  5,  6],\n",
              "        [ 6,  8, 10, 12]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKGd0CmWD8O9"
      },
      "source": [
        "### 2.9 Batch Matrix Multiplication\n",
        "$$C_{ijl} = \\sum_{k} A_{ijk}B_{ikl}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Q9pqxpEfnR",
        "outputId": "c8e1021f-911c-4662-9a90-500e7fa9dfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "a = tr.randn(3,2,5)\n",
        "b = tr.randn(3,5,3)\n",
        "print(a)\n",
        "print(b)\n",
        "tr.einsum('ijk,ikl->ijl', [a, b])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.6552,  0.1795, -2.3108,  0.3509, -2.4135],\n",
            "         [-0.8157, -1.3631,  0.7683, -0.8668,  0.1366]],\n",
            "\n",
            "        [[ 0.9263, -0.2823, -1.2426,  1.4459,  0.7716],\n",
            "         [-0.4063, -0.6770, -0.8384, -0.1709,  0.3847]],\n",
            "\n",
            "        [[-0.8797,  0.8190,  0.9115, -0.0935, -1.7566],\n",
            "         [ 1.7730, -0.0858, -1.3908, -0.3554,  1.2814]]])\n",
            "tensor([[[ 0.0729,  0.6197,  0.8966],\n",
            "         [-0.8856,  0.0655, -1.2936],\n",
            "         [-1.5492,  0.4757, -0.9978],\n",
            "         [-1.3782, -1.4919, -1.2327],\n",
            "         [-0.1998, -0.0917,  0.6421]],\n",
            "\n",
            "        [[ 1.5846,  0.4726, -0.0457],\n",
            "         [ 0.9825,  1.6021, -0.4993],\n",
            "         [-1.3244,  0.8215, -0.1822],\n",
            "         [ 2.6278,  1.9126, -1.9630],\n",
            "         [-0.0788,  0.6109, -0.0908]],\n",
            "\n",
            "        [[ 0.0265, -0.2697,  1.6345],\n",
            "         [-0.3073,  0.7065, -1.7149],\n",
            "         [ 1.7637, -0.0542,  0.1717],\n",
            "         [ 2.2155,  0.0635,  0.1447],\n",
            "         [ 1.2697, -0.0547,  2.6335]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 3.5401, -0.3641,  1.5754],\n",
              "         [ 1.1248,  1.0514,  1.4215]],\n",
              "\n",
              "        [[ 6.5748,  2.2015, -2.5833],\n",
              "         [-0.6780, -2.0572,  0.8098]],\n",
              "\n",
              "        [[-1.1049,  0.8567, -7.3254],\n",
              "         [-1.5401, -0.5563,  6.1294]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9vlyYaIEq4A"
      },
      "source": [
        "### 2.10 Tensor Contraction\n",
        "For example, if we have two tensors, an order-$n$tensor ${\\cal A}\\in\\mathbb{R}^{I_1\\times\\dots\\times I_n}$ and an order-$m$ tensor ${\\cal B}\\in\\mathbb{R}^{J_1\\times\\dots\\times J_m}$, where $n=4,m=5$ and assume that $I_2=J_3$ and $I_3=J_5$. We can multiply the two tensors in these two dimensions (2,3 of ${\\cal A}$ and 3,5 of ${\\cal B}$) resulting in anew tensor ${\\cal C}\\in\\mathbb{R}^{I_1\\times I_4 \\times J_1\\times J_2 \\times J_4}$:\n",
        "# $$C_{pstuv} = \\sum_q\\sum_r A_{pqrs}B_{tuqvr}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dliwd_22GSHR",
        "outputId": "2323e10c-5cc2-452f-95cf-fdf3dbd90045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "A = tr.randn(2,3,5,7)\n",
        "B = tr.randn(11,13,3,17,5)\n",
        "tr.einsum('pqrs,tuqvr->pstuv', [A, B]).shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 7, 11, 13, 17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqF_LG-5Gg5g"
      },
      "source": [
        "### 2.11 Bilinear Transformation\n",
        "$$D_{ij} = \\sum_k\\sum_l A_{ik}B_{jkl}C_{il}:=A_{ik}B_{jkl}C_{il}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxBAp2wUG69H",
        "outputId": "da88e16d-383a-4b97-cd5e-247f4ba2362d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "a = tr.randn(3,4)\n",
        "b = tr.randn(5,4,7)\n",
        "c = tr.randn(3,7)\n",
        "tr.einsum('ik,jkl,il->ij', [a, b, c])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.7615,  0.7483, -1.1445, -1.7901,  3.2181],\n",
              "        [ 6.5693,  2.6666, -0.2932, -1.6851,  0.7707],\n",
              "        [ 0.4451,  1.1593, -1.3036,  4.0214,  3.3757]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyR8R1IzLcS4"
      },
      "source": [
        "### 2.12*\n",
        "New Update: Diagnal of a matrix\n",
        "$$A_{ii}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whvyu9fLH5_-",
        "outputId": "d07b1eb7-2d2f-44bb-f74b-29b45db33893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "a = tr.randn(3,3)\n",
        "print(a)\n",
        "tr.einsum('ii->i',a)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5258, -0.2254,  1.0018],\n",
            "        [-0.8506,  1.2909,  0.4217],\n",
            "        [ 0.4302,  1.1059,  0.6009]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5258,  1.2909,  0.6009])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}